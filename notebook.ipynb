{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17ec8d6a-4218-49b9-a549-0977cec82967",
   "metadata": {
    "id": "MVpsYfWg3z0B"
   },
   "source": [
    "# PW1 - Handwritten character recognition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d682452d-e56e-4de8-a420-4418d63790a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your name here (e.g. \"Edmond Dant√®s\") so I can grade your work\n",
    "your_name = \"Laure Monfraix\"\n",
    "assert your_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8538cf7-81e0-481a-8059-be38b611aafb",
   "metadata": {
    "id": "8CcAqNjJ3z0F"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import math, sys, os, torch, torchvision\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c864b86e-6e6b-4d8a-82c8-6822072a676f",
   "metadata": {
    "id": "3Wxb9pdV3z0F"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gpu: False \n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Using gpu: %s ' % torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa038da6-b812-4053-9b72-8ff97ceb3b9b",
   "metadata": {
    "id": "1Sjq8zzf3z0G"
   },
   "source": [
    "We will be training many models. Select a number of epochs to train each model. If you are using a slow machine, or if you want to restart training often and have many development iterations, we suggest `NUM_EPOCH = 2`. If you are using a fast machine, or have a GPU available, of if you are confident that you can write accurate code first try, you will get better accuracies by increasing this constant. You could be able to afford up to `NUM_EPOCH = 10`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "137adce6-13cc-4ccc-aaf3-42230e322a9b",
   "metadata": {
    "id": "L9CF0H4O3z0G"
   },
   "outputs": [],
   "source": [
    "NUM_EPOCH = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce850e9-ef4e-4323-af2d-be6b94e98994",
   "metadata": {
    "id": "65e20f5e"
   },
   "source": [
    "# Part A - Linear, MLP, and CNN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05aff4bd-8b1d-4531-89d8-64ce4e2b6357",
   "metadata": {
    "id": "KSAiV2ov3z0H"
   },
   "source": [
    "## Handwritten digit recognition dataset\n",
    "\n",
    "We will use the MNIST database (Modified National Institute of Standards and Technology database). It contains tens of thousands of pictures of handwritten digits. This database was compiled in 1994, as part of the effort in the 1990s to standardize automation of sorting devices with human input, for instance sorting mail with handwritten postal codes at the post office. This is now often considered one of the first real successes of neural networks, and the first easy example on which performance of new such algorithms is tested."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3429898a-0f57-4cdf-9aa6-7b1121ee4e53",
   "metadata": {},
   "source": [
    "Load the dataset (train and test splits) using `torchvision`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "59e1c523-4b78-492a-b103-2861af8c3d89",
   "metadata": {
    "id": "Zu3hU4dQ3z0H"
   },
   "outputs": [],
   "source": [
    "root_dir = './data/MNIST/'\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "trainset = datasets.MNIST(root=root_dir, train=True, download=True, transform=transform)\n",
    "\n",
    "testset = datasets.MNIST(root=root_dir, train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77fbaba-b01f-46d0-a1d7-47c59faaf042",
   "metadata": {},
   "source": [
    "How many examples in each split? \n",
    "\n",
    "Plot the first image and label of the training set using `matplotlib`\n",
    "\n",
    "What is the input dimension?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "083f07f4-e129-4e9b-b26e-a32fd4bdb99d",
   "metadata": {
    "id": "9fgMls5P3z0I",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 examples in the train set\n",
      "10000 examples in the test set\n",
      "Label: 5\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### YOUR CODE HERE ###\n",
    "\n",
    "print(f'{len(trainset)} examples in the train set') # 60 000 examples\n",
    "print(f'{len(testset)} examples in the test set') # 10 000 examples\n",
    "\n",
    "# First image and label\n",
    "image, label = trainset[0]\n",
    "\n",
    "plt.imshow(image.squeeze(), cmap = 'gray')\n",
    "print('Label:', label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc2fbd26-b017-435a-822e-ad382eabd8a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input dimension: torch.Size([1, 28, 28]), Label: 5\n"
     ]
    }
   ],
   "source": [
    "### YOUR CODE HERE ###\n",
    "\n",
    "# Input dimension\n",
    "\n",
    "image, label = trainset[0]\n",
    "print(f'Input dimension: {image.shape}, Label: {label}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6380c03-1427-4dea-974e-5a38621ea6c1",
   "metadata": {
    "id": "Guv5_hY63z0L"
   },
   "source": [
    "# A.1 - Linear features\n",
    "\n",
    "We start with a very simple model, linear with respect to pixel values.\n",
    "Use a `preprocess` function to downsample the image to 7x7 pixels, then flatten it and use a `torch.nn.Linear` model.\n",
    "\n",
    "The torch average-pooling function is `torch.nn.functional.avg_pool2d`, check the documentation to set the arguments properly.\n",
    "DO NOT use your implementation of average-pooling, it would take prohibitively long to train and you would not finish the practical.\n",
    "If the training takes too long, go back to the first section and lower the `NUM_EPOCH` constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f37373a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def preprocess(image):\n",
    "    # Downsample the image to 7x7 using average pooling\n",
    "    downsampled = F.avg_pool2d(image.unsqueeze(0), kernel_size=4).squeeze(0)\n",
    "    flattened = downsampled.view(-1)\n",
    "    return flattened"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2bb8e5d-7d84-4a59-aa5d-e942ffa22aa8",
   "metadata": {},
   "source": [
    "Again, use matplotlib to visualize an example of downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ac111d5c-dfa2-44e2-9a57-f2f4c2caff2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### YOUR CODE HERE ###\n",
    "# Downsample the image \n",
    "downsampled_image = preprocess(image)\n",
    "\n",
    "# Reshape the downsampled image to 7x7\n",
    "downsampled_image_reshaped = downsampled_image.view(7, 7)\n",
    "\n",
    "# Plot the downsampled image\n",
    "plt.imshow(downsampled_image_reshaped, cmap='gray')\n",
    "plt.title(\"Downsampled Image (7x7)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6aa4adcb-be17-4f0d-ba9f-4da062227230",
   "metadata": {
    "id": "2v3GqEPU3z0L"
   },
   "outputs": [],
   "source": [
    "### YOUR ( MODEL / PREPROCESSING ) CODE HERE ###\n",
    "class LinearModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LinearModel, self).__init__()\n",
    "        self.fc = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5becae4-e27f-43ed-a1c5-ced8c16f4cac",
   "metadata": {
    "id": "qeWZ7DeNMG20"
   },
   "source": [
    "## A.2 - Loss and optimizer\n",
    "Create a cross entropy loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a85b789e",
   "metadata": {
    "id": "a85b789e"
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43aec31b-3d2b-4b29-ad85-e88a6e25660a",
   "metadata": {
    "id": "ZCnlsh9iMhx_"
   },
   "source": [
    "## A.3 - Training and testing loops\n",
    "Finally, create the functions `train(model, epoch, preprocess, optimizer)` and `test(model)` to train (one epoch with SGD and a learning rate of $10^{-3}$) and test your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "438743f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epoch, preprocess, optimizer):\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        # Preprocess the data\n",
    "        data = torch.stack([preprocess(img) for img in data])\n",
    "        # Forward pass\n",
    "        output = model(data)\n",
    "        # Compute loss\n",
    "        loss = criterion(output, target)\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # Compute accuracy\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        total += target.size(0)\n",
    "    accuracy = 100. * correct / total\n",
    "    print(f\"Train Epoch: {epoch + 1} Accuracy: {accuracy:.2f}%\")\n",
    "    return optimizer, accuracy\n",
    "\n",
    "def test(model, preprocess):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            # Preprocess the data\n",
    "            data = torch.stack([preprocess(img) for img in data])\n",
    "            # Forward pass\n",
    "            output = model(data)\n",
    "            # Compute accuracy\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            total += target.size(0)\n",
    "    accuracy = 100. * correct / total\n",
    "    print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa359382-2580-44ae-bcdb-3f18cf1f4c61",
   "metadata": {
    "id": "_t4SiXk33z0L"
   },
   "source": [
    "You should get at least 85\\% test accuracy even with only 2 epochs. We will be aiming for around 95\\% test accuracy and above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6f12bf85-45c6-41d9-87f3-0601bc4b6339",
   "metadata": {
    "id": "nBmfvtl6UbUe",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 Accuracy: 82.26%\n",
      "Test Accuracy: 87.02%\n",
      "Epoch 1/2, Train Accuracy: 82.26%, Test Accuracy: 87.02%\n",
      "Train Epoch: 2 Accuracy: 86.26%\n",
      "Test Accuracy: 87.59%\n",
      "Epoch 2/2, Train Accuracy: 86.26%, Test Accuracy: 87.59%\n"
     ]
    }
   ],
   "source": [
    "### YOUR CODE HERE ###\n",
    "# Model\n",
    "input_dim = 7 * 7  # Flattened 7x7 image\n",
    "output_dim = 10    # Number of classes\n",
    "\n",
    "model = LinearModel(input_dim, output_dim).to(device)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
    "\n",
    "# Training\n",
    "for epoch in range(NUM_EPOCH):\n",
    "    optimizer, train_accuracy = train(model, epoch, preprocess, optimizer)\n",
    "    test_accuracy = test(model, preprocess)\n",
    "    print(f\"Epoch {epoch + 1}/{NUM_EPOCH}, Train Accuracy: {train_accuracy:.2f}%, Test Accuracy: {test_accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf28bb4e-7178-4340-9247-f69591e86dcf",
   "metadata": {
    "id": "RrwYAMMBEUPN"
   },
   "source": [
    "## A.4 - Multi-layer perceptron (MLP)\n",
    "\n",
    "Create a class MLP that creates an MLP of given width and depth, and use it to create a 3-layer MLP of width $100$. We will assume that `width > 0` and `depth > 0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "79cb6479-d475-4f0e-b0f7-fdd107d9e835",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e8353cd9",
    "outputId": "c7f5eeaf-0638-45c3-842e-4372d21ff712"
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, width, depth):\n",
    "        super(MLP, self).__init__()\n",
    "        layers = []\n",
    "        layers.append(nn.Linear(input_dim, width))\n",
    "        layers.append(nn.ReLU())\n",
    "        for _ in range(depth - 1):\n",
    "            layers.append(nn.Linear(width, width))\n",
    "            layers.append(nn.ReLU())\n",
    "        layers.append(nn.Linear(width, output_dim))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Create a 3-layer MLP with width 100\n",
    "width = 100\n",
    "depth = 3\n",
    "mlp_model = MLP(input_dim, output_dim, width, depth).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9a267a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 Accuracy: 82.94%\n",
      "Test Accuracy: 91.91%\n",
      "Epoch 1/5, Train Accuracy: 82.94%, Test Accuracy: 91.91%\n",
      "Train Epoch: 2 Accuracy: 92.65%\n",
      "Test Accuracy: 92.89%\n",
      "Epoch 2/5, Train Accuracy: 92.65%, Test Accuracy: 92.89%\n",
      "Train Epoch: 3 Accuracy: 94.00%\n",
      "Test Accuracy: 94.79%\n",
      "Epoch 3/5, Train Accuracy: 94.00%, Test Accuracy: 94.79%\n",
      "Train Epoch: 4 Accuracy: 94.55%\n",
      "Test Accuracy: 94.94%\n",
      "Epoch 4/5, Train Accuracy: 94.55%, Test Accuracy: 94.94%\n",
      "Train Epoch: 5 Accuracy: 95.06%\n",
      "Test Accuracy: 94.83%\n",
      "Epoch 5/5, Train Accuracy: 95.06%, Test Accuracy: 94.83%\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCH = 5\n",
    "\n",
    "optimizer = torch.optim.SGD(mlp_model.parameters(), lr=0.1, momentum=0.9)\n",
    "\n",
    "# Training the MLP model\n",
    "for epoch in range(NUM_EPOCH):\n",
    "    optimizer, train_accuracy = train(mlp_model, epoch, preprocess, optimizer) \n",
    "    test_accuracy = test(mlp_model, preprocess)  \n",
    "    print(f\"Epoch {epoch + 1}/{NUM_EPOCH}, Train Accuracy: {train_accuracy:.2f}%, Test Accuracy: {test_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42119bc1",
   "metadata": {},
   "source": [
    "### Add Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b2c451",
   "metadata": {},
   "source": [
    "We test the addition of dropout layers after each hidden MLP layer to limit overlearning. The aim is to improve the generalization capacity of the model and increase its accuracy on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a050271f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the MLP model with dropout\n",
    "class MLP2(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, width, depth, dropout_p=0.5):\n",
    "        super(MLP2, self).__init__()\n",
    "        layers = []\n",
    "        layers.append(nn.Linear(input_dim, width))\n",
    "        layers.append(nn.ReLU())\n",
    "        layers.append(nn.Dropout(dropout_p))  # dropout after first layer\n",
    "\n",
    "        for _ in range(depth - 1):\n",
    "            layers.append(nn.Linear(width, width))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout_p))  # dropout after each hiddden layer\n",
    "\n",
    "        layers.append(nn.Linear(width, output_dim)) \n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "width = 100\n",
    "depth = 3\n",
    "dropout_p = 0.5\n",
    "\n",
    "mlp_model_dropout = MLP2(input_dim, output_dim, width, depth, dropout_p=dropout_p).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9f9abdc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 Accuracy: 64.56%\n",
      "Test Accuracy: 85.60%\n",
      "Epoch 1/5, Train Accuracy: 64.56%, Test Accuracy: 85.60%\n",
      "Train Epoch: 2 Accuracy: 77.58%\n",
      "Test Accuracy: 87.69%\n",
      "Epoch 2/5, Train Accuracy: 77.58%, Test Accuracy: 87.69%\n",
      "Train Epoch: 3 Accuracy: 78.33%\n",
      "Test Accuracy: 89.84%\n",
      "Epoch 3/5, Train Accuracy: 78.33%, Test Accuracy: 89.84%\n",
      "Train Epoch: 4 Accuracy: 79.75%\n",
      "Test Accuracy: 89.30%\n",
      "Epoch 4/5, Train Accuracy: 79.75%, Test Accuracy: 89.30%\n",
      "Train Epoch: 5 Accuracy: 80.11%\n",
      "Test Accuracy: 89.90%\n",
      "Epoch 5/5, Train Accuracy: 80.11%, Test Accuracy: 89.90%\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCH = 5\n",
    "\n",
    "optimizer = torch.optim.SGD(mlp_model_dropout.parameters(), lr=0.1, momentum=0.9)\n",
    "\n",
    "# Training the MLP model\n",
    "for epoch in range(NUM_EPOCH):\n",
    "    optimizer, train_accuracy = train(mlp_model_dropout, epoch, preprocess, optimizer) \n",
    "    test_accuracy = test(mlp_model_dropout, preprocess)  \n",
    "    print(f\"Epoch {epoch + 1}/{NUM_EPOCH}, Train Accuracy: {train_accuracy:.2f}%, Test Accuracy: {test_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2c2002",
   "metadata": {},
   "source": [
    "The addition of the Dropout results in a test accuracy of 89.9%, slightly lower than that obtained with the classic MLP, which may be explained by sub-optimization of the model parameters (for example, a dropout rate that is too high or an insufficient number of epochs to compensate for the additional regularization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing lr=0.1, dropout_p=0.3\n",
      "Train Epoch: 1 Accuracy: 75.61%\n",
      "Train Epoch: 2 Accuracy: 87.36%\n",
      "Train Epoch: 3 Accuracy: 88.82%\n",
      "Train Epoch: 4 Accuracy: 89.47%\n",
      "Train Epoch: 5 Accuracy: 90.04%\n",
      "Test Accuracy: 92.94%\n",
      "Test Accuracy: 92.94%\n",
      "\n",
      "Testing lr=0.1, dropout_p=0.5\n",
      "Train Epoch: 1 Accuracy: 64.58%\n",
      "Train Epoch: 2 Accuracy: 77.25%\n",
      "Train Epoch: 3 Accuracy: 79.31%\n",
      "Train Epoch: 4 Accuracy: 79.94%\n",
      "Train Epoch: 5 Accuracy: 80.55%\n",
      "Test Accuracy: 90.22%\n",
      "Test Accuracy: 90.22%\n",
      "\n",
      "Testing lr=0.1, dropout_p=0.7\n",
      "Train Epoch: 1 Accuracy: 29.59%\n",
      "Train Epoch: 2 Accuracy: 24.13%\n",
      "Train Epoch: 3 Accuracy: 18.82%\n",
      "Train Epoch: 4 Accuracy: 16.13%\n",
      "Train Epoch: 5 Accuracy: 17.38%\n",
      "Test Accuracy: 24.57%\n",
      "Test Accuracy: 24.57%\n",
      "\n",
      "Testing lr=0.01, dropout_p=0.3\n",
      "Train Epoch: 1 Accuracy: 46.58%\n",
      "Train Epoch: 2 Accuracy: 81.00%\n",
      "Train Epoch: 3 Accuracy: 86.62%\n",
      "Train Epoch: 4 Accuracy: 88.59%\n",
      "Train Epoch: 5 Accuracy: 89.82%\n",
      "Test Accuracy: 93.36%\n",
      "Test Accuracy: 93.36%\n",
      "\n",
      "Testing lr=0.01, dropout_p=0.5\n",
      "Train Epoch: 1 Accuracy: 38.23%\n",
      "Train Epoch: 2 Accuracy: 73.61%\n",
      "Train Epoch: 3 Accuracy: 81.14%\n",
      "Train Epoch: 4 Accuracy: 83.71%\n",
      "Train Epoch: 5 Accuracy: 85.15%\n",
      "Test Accuracy: 91.76%\n",
      "Test Accuracy: 91.76%\n",
      "\n",
      "Testing lr=0.01, dropout_p=0.7\n",
      "Train Epoch: 1 Accuracy: 21.62%\n",
      "Train Epoch: 2 Accuracy: 53.11%\n",
      "Train Epoch: 3 Accuracy: 66.95%\n",
      "Train Epoch: 4 Accuracy: 72.23%\n",
      "Train Epoch: 5 Accuracy: 74.94%\n",
      "Test Accuracy: 88.85%\n",
      "Test Accuracy: 88.85%\n",
      "\n",
      "Testing lr=0.001, dropout_p=0.3\n",
      "Train Epoch: 1 Accuracy: 15.92%\n",
      "Train Epoch: 2 Accuracy: 24.77%\n",
      "Train Epoch: 3 Accuracy: 29.69%\n",
      "Train Epoch: 4 Accuracy: 41.83%\n",
      "Train Epoch: 5 Accuracy: 53.31%\n",
      "Test Accuracy: 67.22%\n",
      "Test Accuracy: 67.22%\n",
      "\n",
      "Testing lr=0.001, dropout_p=0.5\n",
      "Train Epoch: 1 Accuracy: 11.87%\n",
      "Train Epoch: 2 Accuracy: 17.75%\n",
      "Train Epoch: 3 Accuracy: 25.31%\n",
      "Train Epoch: 4 Accuracy: 33.69%\n",
      "Train Epoch: 5 Accuracy: 41.01%\n",
      "Test Accuracy: 56.25%\n",
      "Test Accuracy: 56.25%\n",
      "\n",
      "Testing lr=0.001, dropout_p=0.7\n",
      "Train Epoch: 1 Accuracy: 10.86%\n",
      "Train Epoch: 2 Accuracy: 13.36%\n",
      "Train Epoch: 3 Accuracy: 15.61%\n",
      "Train Epoch: 4 Accuracy: 18.25%\n",
      "Train Epoch: 5 Accuracy: 22.71%\n",
      "Test Accuracy: 32.35%\n",
      "Test Accuracy: 32.35%\n",
      "\n",
      "Best Hyperparameters found:\n",
      "{'learning_rate': 0.01, 'dropout_p': 0.3}\n",
      "Best Test Accuracy: 93.36%\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "class MLP_opti(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, width, depth, dropout_p):\n",
    "        super(MLP_opti, self).__init__()\n",
    "        layers = []\n",
    "        layers.append(nn.Linear(input_dim, width))\n",
    "        layers.append(nn.ReLU())\n",
    "        layers.append(nn.Dropout(dropout_p))\n",
    "        for _ in range(depth - 1):\n",
    "            layers.append(nn.Linear(width, width))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout_p))\n",
    "        layers.append(nn.Linear(width, output_dim))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Hyperparameters to test\n",
    "learning_rates = [0.1, 0.01, 0.001]\n",
    "dropout_rates = [0.3, 0.5, 0.7]\n",
    "\n",
    "best_accuracy = 0\n",
    "best_params = {}\n",
    "\n",
    "# Loop through hyperparameters\n",
    "for lr in learning_rates:\n",
    "    for dropout_p in dropout_rates:\n",
    "        print(f\"\\nTesting lr={lr}, dropout_p={dropout_p}\")\n",
    "        \n",
    "        model = MLP_opti(input_dim, output_dim, width=100, depth=3, dropout_p=dropout_p).to(device)\n",
    "        \n",
    "        optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "        \n",
    "        # Training\n",
    "        for epoch in range(5):  \n",
    "            optimizer, train_accuracy = train(model, epoch, preprocess, optimizer)\n",
    "        \n",
    "        # Evaluation\n",
    "        test_accuracy = test(model, preprocess)\n",
    "        \n",
    "        print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n",
    "        \n",
    "        # Save the best parameters based on test accuracy\n",
    "        if test_accuracy > best_accuracy:\n",
    "            best_accuracy = test_accuracy\n",
    "            best_params = {'learning_rate': lr, 'dropout_p': dropout_p}\n",
    "\n",
    "print(\"\\nBest Hyperparameters found:\")\n",
    "print(best_params)\n",
    "print(f\"Best Test Accuracy: {best_accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd9d168",
   "metadata": {},
   "source": [
    "Despite the optimization of hyperparameters, the addition of Dropout does not bring any significant gain in performance over the MLP without Dropout. This suggests that the base MLP was not strongly prone to overfitting on this dataset, probably due to the size of the dataset or the nature of the task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ca5a11-93e4-47ab-81f1-e4ee3cae45c9",
   "metadata": {
    "id": "v1czyC9R3z0R"
   },
   "source": [
    "# A.5 - Deep convolutional model\n",
    "\n",
    "Write a convolutional model, with learned features.\n",
    "Use two layers, one convolutional with 8 filters of size 3x3, then take a relu and max-pool with kernel size 2, and finally flatten and add a Linear layer. You can use the identity as pre-processing function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4933e318-5521-4bf8-b011-bdb95ed0d8b0",
   "metadata": {},
   "source": [
    "\n",
    "Here is a little animation to remind you of the sliding window principle of convolutions.\n",
    "\n",
    "![conv](https://github.com//vdumoulin/conv_arithmetic/raw/master/gif/no_padding_no_strides.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c87b30-36d7-4567-b009-a41413afac5b",
   "metadata": {
    "id": "l4QOi_oe3z0R"
   },
   "outputs": [],
   "source": [
    "class ConvModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=8, kernel_size=3)  \n",
    "        self.relu = nn.ReLU() \n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2) \n",
    "        self.flatten = nn.Flatten()  \n",
    "        self.fc = nn.Linear(8 * 13 * 13, 10) \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Model\n",
    "conv_model = ConvModel().to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0313eed-03ad-461d-9ddb-bb690c631149",
   "metadata": {
    "id": "pbQ1LUqf3z0R"
   },
   "source": [
    "You should be able to get around 97\\% to 98\\% accuracy with this model. Try increasing the NUM_EPOCH constant and watch what happens to test accuracy and train accuracy as training progresses further.\n",
    "\n",
    "Write a deeper convolutional model, with one convolutional layer as previously, but three linear layers with relu activations after that.\n",
    "Use `h = 100` hidden neurons. How does the test accuracy compare with the previous two-layer network ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f081fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 Accuracy: 94.37%\n",
      "Test Accuracy: 97.39%\n",
      "Epoch 1/5, Train Accuracy: 94.37%, Test Accuracy: 97.39%\n",
      "Train Epoch: 2 Accuracy: 97.34%\n",
      "Test Accuracy: 97.70%\n",
      "Epoch 2/5, Train Accuracy: 97.34%, Test Accuracy: 97.70%\n",
      "Train Epoch: 3 Accuracy: 97.88%\n",
      "Test Accuracy: 97.64%\n",
      "Epoch 3/5, Train Accuracy: 97.88%, Test Accuracy: 97.64%\n",
      "Train Epoch: 4 Accuracy: 98.05%\n",
      "Test Accuracy: 97.73%\n",
      "Epoch 4/5, Train Accuracy: 98.05%, Test Accuracy: 97.73%\n",
      "Train Epoch: 5 Accuracy: 98.29%\n",
      "Test Accuracy: 97.72%\n",
      "Epoch 5/5, Train Accuracy: 98.29%, Test Accuracy: 97.72%\n"
     ]
    }
   ],
   "source": [
    "# Conv model with 2 layers\n",
    "NUM_EPOCH = 5 \n",
    "\n",
    "optimizer = torch.optim.SGD(conv_model.parameters(), lr=0.1, momentum=0.9)\n",
    "\n",
    "# Training \n",
    "for epoch in range(NUM_EPOCH):\n",
    "    optimizer, train_accuracy = train(conv_model, epoch, lambda x: x, optimizer)\n",
    "    test_accuracy = test(conv_model, lambda x: x)\n",
    "    print(f\"Epoch {epoch + 1}/{NUM_EPOCH}, Train Accuracy: {train_accuracy:.2f}%, Test Accuracy: {test_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792791e1-0514-4749-a3fb-d27eb10a1bd2",
   "metadata": {
    "id": "YM-OhC123z0R"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 Accuracy: 91.89%\n",
      "Test Accuracy: 96.57%\n",
      "Epoch 1/5, Train Accuracy: 91.89%, Test Accuracy: 96.57%\n",
      "Train Epoch: 2 Accuracy: 97.65%\n",
      "Test Accuracy: 97.11%\n",
      "Epoch 2/5, Train Accuracy: 97.65%, Test Accuracy: 97.11%\n",
      "Train Epoch: 3 Accuracy: 98.18%\n",
      "Test Accuracy: 97.74%\n",
      "Epoch 3/5, Train Accuracy: 98.18%, Test Accuracy: 97.74%\n",
      "Train Epoch: 4 Accuracy: 98.60%\n",
      "Test Accuracy: 97.98%\n",
      "Epoch 4/5, Train Accuracy: 98.60%, Test Accuracy: 97.98%\n",
      "Train Epoch: 5 Accuracy: 98.83%\n",
      "Test Accuracy: 98.09%\n",
      "Epoch 5/5, Train Accuracy: 98.83%, Test Accuracy: 98.09%\n"
     ]
    }
   ],
   "source": [
    "# Conv model with 3 layers\n",
    "class ConvDeepModel(torch.nn.Module):\n",
    "    def __init__(self, h=100):\n",
    "        super(ConvDeepModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=8, kernel_size=3)  \n",
    "        self.relu = nn.ReLU()  # ReLU activation\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2)  \n",
    "        self.flatten = nn.Flatten() \n",
    "        self.fc1 = nn.Linear(8 * 13 * 13, h) \n",
    "        self.fc2 = nn.Linear(h, h)  \n",
    "        self.fc3 = nn.Linear(h, 10) \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Model\n",
    "h = 100  # Hidden neurons\n",
    "conv_deep_model = ConvDeepModel(h=h).to(device)\n",
    "\n",
    "optimizer = torch.optim.SGD(conv_deep_model.parameters(), lr=0.1, momentum=0.9)\n",
    "\n",
    "# Training \n",
    "for epoch in range(NUM_EPOCH):\n",
    "    optimizer, train_accuracy = train(conv_deep_model, epoch, lambda x: x, optimizer)\n",
    "    test_accuracy = test(conv_deep_model, lambda x: x)\n",
    "    print(f\"Epoch {epoch + 1}/{NUM_EPOCH}, Train Accuracy: {train_accuracy:.2f}%, Test Accuracy: {test_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dadc31b",
   "metadata": {},
   "source": [
    "Logically, with 3 layers, test accuracy increases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fd763b-b36a-461c-ad34-f472e62ce46d",
   "metadata": {},
   "source": [
    "## A.6 Visualisations of convolutions\n",
    "\n",
    "After training your model, let's see what features it has learned!\n",
    "\n",
    "Plot an image from the test set then plot all 8 feature maps extracted by the convolutional layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0e5284c2-4210-4ccc-bf05-5e722bdabf63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### YOUR CODE HERE ###\n",
    "image, label = testset[0]\n",
    "image = image.unsqueeze(0).to(device)\n",
    "\n",
    "output = conv_model.conv1(image)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.subplot(3, 3, 1)\n",
    "plt.imshow(image.cpu().squeeze(), cmap='gray')\n",
    "plt.title(f\"Label: {label}\")\n",
    "plt.axis('off')\n",
    "\n",
    "for i in range(8):\n",
    "    plt.subplot(3, 3, i + 2)\n",
    "    plt.imshow(output[0, i].cpu().detach(), cmap='viridis')\n",
    "    plt.title(f\"Map {i + 1}\")\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc457ad1-3240-4ffb-a8f3-98c6554dfce5",
   "metadata": {
    "id": "riu_K1at3z0R"
   },
   "source": [
    "# Part B - Residual models\n",
    "\n",
    "## B.1 - Residual blocks\n",
    "\n",
    "Write a residual block with two linear layers to learn a function $\\mathbb{R}^d \\to \\mathbb{R}^d$ with $h < d$ hidden neurons.\n",
    "Write a convolutional residual block with the same idea. What hyperparameter acts as the number of hidden neurons in convolutional blocks ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec298d4-4372-4a1f-be53-a278d051c0f6",
   "metadata": {
    "id": "gkCILVwd3z0R"
   },
   "outputs": [],
   "source": [
    "class ResidualBlock(torch.nn.Module):\n",
    "    def __init__(self, d, h):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.fc1 = nn.Linear(d, h)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(h, d)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x  # input for the residual connection\n",
    "        out = self.fc1(x)  \n",
    "        out = self.relu(out)  \n",
    "        out = self.fc2(out)  \n",
    "        out += residual  # residual connection\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3890dedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n",
    "        super(ConvResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size, stride, padding)\n",
    "        self.shortcut = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1) if in_channels != out_channels else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = self.shortcut(x)\n",
    "        out = self.conv1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out += residual\n",
    "        return self.relu(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf0d79c",
   "metadata": {},
   "source": [
    "In a convolutional block, the out_channels parameter determines the number of filters learned, playing a role equivalent to the number of neurons in a hidden layer of an MLP. The higher out_channels is, the more varied and complex patterns the model can detect."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc0097d-269c-40f4-b182-bdc79bd5c512",
   "metadata": {
    "id": "huKWOvVc3z0S"
   },
   "source": [
    "## B.2 - Stacking residual blocks\n",
    "\n",
    "Use a single convolution layer, followed by a relu and max-pool, then an arbitrary number of residual blocks as defined above, and finish with a linear layer. Can you match the accuracy of the two-layer network ? Can you exceed it ? What happens when you increase the number of layers ? Look at the details of the ResNet architecture on the lecture's slides to get an idea of how to increase the number of hidden neurons and the number of layers. One of the strengths of ResNets was there relatively low number of parameters compared\n",
    "to a multi-layer architecture like that of the previous section, does this show in your experiments ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33da5a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 Accuracy: 94.38%\n",
      "Test Accuracy: 96.93%\n",
      "Epoch 1/5, Train Accuracy: 94.38%, Test Accuracy: 96.93%\n",
      "Train Epoch: 2 Accuracy: 97.02%\n",
      "Test Accuracy: 97.33%\n",
      "Epoch 2/5, Train Accuracy: 97.02%, Test Accuracy: 97.33%\n",
      "Train Epoch: 3 Accuracy: 97.39%\n",
      "Test Accuracy: 97.80%\n",
      "Epoch 3/5, Train Accuracy: 97.39%, Test Accuracy: 97.80%\n",
      "Train Epoch: 4 Accuracy: 97.81%\n",
      "Test Accuracy: 97.81%\n",
      "Epoch 4/5, Train Accuracy: 97.81%, Test Accuracy: 97.81%\n",
      "Train Epoch: 5 Accuracy: 97.79%\n",
      "Test Accuracy: 97.85%\n",
      "Epoch 5/5, Train Accuracy: 97.79%, Test Accuracy: 97.85%\n"
     ]
    }
   ],
   "source": [
    "class ResidualConvNet(nn.Module):\n",
    "    def __init__(self, num_residual_blocks, in_channels=1, out_channels=8, kernel_size=3, hidden_dim=100, num_classes=10):\n",
    "        super(ResidualConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2)\n",
    "        self.residual_blocks = nn.Sequential(\n",
    "            *[ConvResidualBlock(out_channels, out_channels) for _ in range(num_residual_blocks)]\n",
    "        )\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(out_channels * 14 * 14, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.residual_blocks(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Model\n",
    "num_residual_blocks = 3  \n",
    "residual_conv_net = ResidualConvNet(num_residual_blocks=num_residual_blocks).to(device)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.SGD(residual_conv_net.parameters(), lr=0.1, momentum=0.9)\n",
    "\n",
    "# Training\n",
    "for epoch in range(NUM_EPOCH):\n",
    "    optimizer, train_accuracy = train(residual_conv_net, epoch, lambda x: x, optimizer)\n",
    "    test_accuracy = test(residual_conv_net, lambda x: x)\n",
    "    print(f\"Epoch {epoch + 1}/{NUM_EPOCH}, Train Accuracy: {train_accuracy:.2f}%, Test Accuracy: {test_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f571dd6a",
   "metadata": {},
   "source": [
    "Yes, the accuracy of the two-layer model can be matched or exceeded by adding layers, especially with residual blocks. Without them, depth often leads to a drop in performance due to the vanishing gradient, which blocks learning. Residual blocks overcome this problem by facilitating gradient propagation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0d4de4-11e8-490c-8262-064b3e841fa5",
   "metadata": {
    "id": "U4gg9uWg3z0S"
   },
   "source": [
    "Yes, this is borne out in experiments: despite similar performance (test accuracy ‚âà 94-95%), an MLP with 3 hidden layers of width 100 uses far more parameters than a lighter ResNet. Indeed, with only 2 convolutional layers and residual blocks, similar test accuracy results are achieved, while model complexity is reduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "77b2a317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable parameters for ResNet: 19,274\n",
      "Total trainable parameters for MLP: 26,210\n"
     ]
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "info = summary(residual_conv_net, input_size=(1, 1, 28, 28), depth=3)\n",
    "print(f\"Total trainable parameters for ResNet: {info.total_params:,}\")\n",
    "\n",
    "info2 = summary(mlp_model, input_size=(1, 49))\n",
    "print(f\"Total trainable parameters for MLP: {info2.total_params:,}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b788ae81",
   "metadata": {},
   "source": [
    "Both models achieve similar performance, but the ResNet uses only 19,274 parameters, compared with 26,210 for the MLP."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df418703-b1e1-4276-8ba7-dd5622c7b7cd",
   "metadata": {
    "id": "2nes_ZtBoBu0"
   },
   "source": [
    "# Part C - Reimplementing loss functions\n",
    "\n",
    "## C.0 - Combining losses\n",
    "First, we recall that, for a batch of score vectors $s\\in\\mathbb{R}^{n\\times C}$ and true labels $y\\in[1,C]^n$, **cross entropy** is defined as\n",
    "$$CE(s, y) = -\\frac{1}{n}\\sum_{i=1}^n \\log\\left( \\mbox{softmax}(s_i)_{y_i} \\right)$$\n",
    "\n",
    "where $\\mbox{softmax}(x)_i = \\frac{e^{x_i}}{\\sum_{j=1}^n e^{x_j}}$ is the probability associated to class $i\\in[1,C]$ for a score vector $x\\in\\mathbb{R}^C$.\n",
    "\n",
    "Let's try to compute cross-entropy in three different ways (see the [documentation](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html)):\n",
    "1. Using `nn.CrossEntropyLoss()`.\n",
    "2. Using `nn.NLLLoss()` and `nn.LogSoftmax()`.\n",
    "3. Using `nn.NLLLoss()` and `nn.Softmax()`.\n",
    "\n",
    "Check that the output is the same for all three methods on Gaussian random scores `torch.randn(n_batch, n_classes)` and random labels `torch.randint(0, n_classes, [n_batch])`, where `n_batch=4` and `n_classes=10`. Note that the scores are real valued vectors while the labels are integers corresponding to the true class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b6c172",
   "metadata": {
    "id": "e1b6c172"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss using nn.CrossEntropyLoss(): 3.082906723022461\n",
      "Loss using nn.NLLLoss() and nn.LogSoftmax(): 3.082906723022461\n",
      "Loss using nn.NLLLoss() and nn.Softmax(): 3.0829062461853027\n"
     ]
    }
   ],
   "source": [
    "### YOUR CODE HERE ###\n",
    "# Initialization\n",
    "n_batch = 4\n",
    "n_classes = 10\n",
    "\n",
    "# Random scores and labels\n",
    "scores = torch.randn(n_batch, n_classes)\n",
    "labels = torch.randint(0, n_classes, (n_batch,))\n",
    "\n",
    "# nn.CrossEntropyLoss()\n",
    "criterion_ce = nn.CrossEntropyLoss()\n",
    "loss_ce = criterion_ce(scores, labels)\n",
    "\n",
    "# nn.NLLLoss() and nn.LogSoftmax()\n",
    "log_softmax = nn.LogSoftmax(dim=1)\n",
    "nll_loss = nn.NLLLoss()\n",
    "loss_nll_logsoftmax = nll_loss(log_softmax(scores), labels)\n",
    "\n",
    "# nn.NLLLoss() and nn.Softmax()\n",
    "softmax = nn.Softmax(dim=1)\n",
    "loss_nll_softmax = nll_loss(torch.log(softmax(scores)), labels)\n",
    "\n",
    "\n",
    "print(f\"Loss using nn.CrossEntropyLoss(): {loss_ce.item()}\")\n",
    "print(f\"Loss using nn.NLLLoss() and nn.LogSoftmax(): {loss_nll_logsoftmax.item()}\")\n",
    "print(f\"Loss using nn.NLLLoss() and nn.Softmax(): {loss_nll_softmax.item()}\")\n",
    "\n",
    "# Outputs are the same"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba900c6-f7b2-4179-a2f1-f1eede4b6697",
   "metadata": {
    "id": "TWKaTBVd5ftN"
   },
   "source": [
    "## C.1 - Re-implementation\n",
    "Now re-implement cross-entropy using base functions (`torch.log`, `torch.exp`, `torch.sum`, etc...). Verify that your function returns the same value as Pytorch's implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "EfA-3-E7qwgF",
   "metadata": {
    "id": "EfA-3-E7qwgF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss using custom implementation: 3.082906484603882\n",
      "Loss using nn.CrossEntropyLoss(): 3.082906723022461\n"
     ]
    }
   ],
   "source": [
    "def ce(logits, targets):\n",
    "    ### YOUR CODE HERE ###\n",
    "    exp_logits = torch.exp(logits)\n",
    "    softmax_probs = exp_logits / torch.sum(exp_logits, dim=1, keepdim=True)\n",
    "    \n",
    "    # True class\n",
    "    true_class_probs = softmax_probs[range(len(targets)), targets]\n",
    "    \n",
    "    # Compute loss\n",
    "    loss = -torch.mean(torch.log(true_class_probs))\n",
    "    return loss\n",
    "\n",
    "# Check the results\n",
    "loss_custom = ce(scores, labels)\n",
    "print(f\"Loss using custom implementation: {loss_custom.item()}\")\n",
    "print(f\"Loss using nn.CrossEntropyLoss(): {loss_ce.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011ec13a-330a-4073-99b9-2eb9dd42d1f8",
   "metadata": {
    "id": "OFG0QfKN7WtO"
   },
   "source": [
    "## C.2 - Stability analysis\n",
    "Softmax probabilities can be relatively unstable due to their use of exponentials. Pytorch implementations thus usually use log probas or logits to avoid overflows or floating point errors. Test all methods (including your own) on Gaussian random scores of standard deviation equal to $100$. Which methods are stable? Why? Is it an issue in practice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "741771f5-864d-446a-b654-3b4f5a2598ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss using nn.CrossEntropyLoss(): 100.24188232421875\n",
      "Loss using nn.NLLLoss() and nn.LogSoftmax(): 100.24188232421875\n",
      "Loss using nn.NLLLoss() and nn.Softmax(): inf\n",
      "Loss using custom implementation: nan\n"
     ]
    }
   ],
   "source": [
    "### YOUR CODE HERE ###\n",
    "\n",
    "scores_high_std = torch.randn(n_batch, n_classes) * 100\n",
    "labels_high_std = torch.randint(0, n_classes, (n_batch,))\n",
    "\n",
    "# nn.CrossEntropyLoss()\n",
    "loss_ce_high_std = criterion_ce(scores_high_std, labels_high_std)\n",
    "print(f\"Loss using nn.CrossEntropyLoss(): {loss_ce_high_std.item()}\")\n",
    "\n",
    "\n",
    "# nn.NLLLoss() and nn.LogSoftmax()\n",
    "loss_nll_logsoftmax_high_std = nll_loss(log_softmax(scores_high_std), labels_high_std)\n",
    "print(f\"Loss using nn.NLLLoss() and nn.LogSoftmax(): {loss_nll_logsoftmax_high_std.item()}\")\n",
    "\n",
    "# nn.NLLLoss() and nn.Softmax()\n",
    "\n",
    "loss_nll_softmax_high_std = nll_loss(torch.log(softmax(scores_high_std)), labels_high_std)\n",
    "print(f\"Loss using nn.NLLLoss() and nn.Softmax(): {loss_nll_softmax_high_std.item()}\")\n",
    "\n",
    "# Custom implementation\n",
    "loss_custom_high_std = ce(scores_high_std, labels_high_std)\n",
    "print(f\"Loss using custom implementation: {loss_custom_high_std.item()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d18062e",
   "metadata": {},
   "source": [
    "When applying different cross-entropy calculation methods to very high Gaussian scores (standard deviation 100), only some remain stable. Methods using nn.CrossEntropyLoss() directly or nn.NLLLoss() combined with nn.LogSoftmax() give identical and stable results, as they incorporate the log-sum-exp trick, which prevents overflows when calculating exponentials. On the other hand, methods based on Softmax followed by log, or a naive implementation using torch.exp() like the one initially proposed, return inf or nan, as exponentials of very large values exceed the capacity of floats."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecaaf7c-b21f-4e18-ac53-1a77adbc60bf",
   "metadata": {
    "id": "Y3y4BfwbBIGy"
   },
   "source": [
    "Re-implement a stable version of cross-entropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d00dab-a37e-48da-880f-81f10efdc133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss using stable implementation: 106.2891\n",
      "Loss using nn.CrossEntropyLoss(): 100.2419\n"
     ]
    }
   ],
   "source": [
    "def stable_ce(logits, targets):\n",
    "    ### YOUR CODE HERE ###\n",
    "    \n",
    "    # Apply the log-sum-exp trick for stability\n",
    "    max_logits = torch.max(logits, dim=1, keepdim=True).values\n",
    "    logits_exp = logits - max_logits \n",
    "    log_probs = logits_exp - torch.log(torch.sum(torch.exp(logits_exp), dim=1, keepdim=True))\n",
    "    \n",
    "    # True classes\n",
    "    true_class_log_probs = log_probs[range(len(targets)), targets]\n",
    "    \n",
    "    # Compute the loss\n",
    "    loss = -torch.mean(true_class_log_probs)\n",
    "    return loss\n",
    "\n",
    "\n",
    "# Check the results\n",
    "\n",
    "# classical CrossEntropyLoss \n",
    "criterion_ce = torch.nn.CrossEntropyLoss()\n",
    "loss_ce = criterion_ce(scores_high_std, labels_high_std)\n",
    "\n",
    "# random data \n",
    "scores_high_std = torch.randn(n_batch, n_classes) * 100\n",
    "labels_high_std = torch.randint(0, n_classes, (n_batch,))\n",
    "\n",
    "# custom CrossEntropyLoss \n",
    "\n",
    "loss_stable = stable_ce(scores_high_std, labels_high_std)\n",
    "print(f\"Loss using stable implementation: {loss_stable.item():.4f}\")\n",
    "print(f\"Loss using nn.CrossEntropyLoss(): {loss_ce.item():.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
